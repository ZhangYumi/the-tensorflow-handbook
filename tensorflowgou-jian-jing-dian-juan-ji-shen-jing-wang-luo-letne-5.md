# Tensorflow构建经典卷积神经网络LeNet-5
---
前面我们对卷积神经网络（CNN）以及LeNet-5模型作了一个简单的介绍。本文我们将用Tensorflow构建一个LeNet-5模型，实现手写数字的识别。
### 1.代码整体结构
我们首先从代码的整体封装去理解卷积神经网络以及LeNet-5的结构。回忆一下，一个LeNet-5模型的前向传播过程为：输入层 → 卷积层1 → 池化层1 → 卷积层2 → 池化层2 → 全连接层1 → 全连接层2 → 输出层。神经网络的输入层我们需要初始化权重W和偏移量b，我们将这两个初始化函数进行封装为*get\_weight()*和*get\_bias()*,同时，卷积层与池化层我们这里自定义两个子函数：卷积计算函数_conv2d()_和最大池化计算函数_max_pooling()_。整体代码封装如下图：

![](/assets/TIM截图20180523152147.png)

### 2.参数定义
我们首先定义LeNet-5模型中各层输入输出的size参数以及depth参数。如图，输入层的输入为28×28的灰度图像，因此输入层输入为28×28×1的矩阵，IMAGE_SIZE为28，NUM\_CHANNELS为1。第一层卷积层，我们用5×5×32的过滤器对输入图像进行卷积，CONV1_SIZE为5，CONV1_KERNEL_NUM为32。卷积时采用0填充，因此输出图像为28×28×32。接下来，我们采用2×2的池化矩阵，以步长为2对上面的输出图像进行滑动最大池化，得到14×14×32。到目前，我们已经完成了第一层卷积和第一层最大池化。

接下来，我们将第一层池化的输出结果作为输入进行第二层卷积，此时输入为14×14×32，第二层卷积层过滤器为5×5×64，因此，CONV2_SIZE为5，CONV2_KERNEL_NUM为64，然后同样最大池化，得到输出为7×7×64。最后是全连接层，第一层全连接层的输入为7×7×64。设置全连接层权重参数向量长度为1024，最终输出向量是长度为10的0、1组成的向量。

![](/assets/TIM截图20180523154109.png)

### 3.初始化权重W

![](/assets/TIM截图20180523160520.png)

我们用tf.truncated_normal()函数进行初始化权重W。tf.truncated_normal()返回一个随机数矩阵，这些随机数服从一个截断的正态分布。tf.truncated_normal()的定义为：

```
def truncated_normal(shape,
                     mean=0.0,
                     stddev=1.0,
                     dtype=tf.float32,
                     seed=None,
                     name=None):                     
```
shape是返回的随机数矩阵的形状，mean是均值，stddev是标准差，dtype是数据类型，seed是随机种子，name是返回矩阵的名称。这里我们将shape作为初始化参数，标准差stddev设置为0.1,标准差设置过大导致权重参数分布范围过大，更新不稳定，容易导致梯度爆炸。

### 4.初始化偏移量b

![](/assets/TIM截图20180523162738.png)

get_bias()我们定义两个参数，矩阵形状shape与参数初始化填充值value，默认为0.1。比如get_bias([3,2])将返回一个tensorflow变量，会话中运行该变量得到矩阵：

```
[[0.1,0.1],
 [0.1,0.1],
 [0.1,0.1]
]
```

### 5.