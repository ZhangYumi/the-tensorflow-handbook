# 简单神经网络介绍
---
在构建一个神经网络之前，我们先花几分钟大致了解一下一个神经网络的构成以及运行流程。如图，下面是一个二层神经网络（我们在计算神经网络层数时，不计输入层，只计隐藏层和输出层）。

![](/assets/TIM截图20180430234143.png)

一个神经网络一般由三部分构成：输入层、隐藏层以及输出层。第一层为输入层，最后一层为输出层，输入层与输出层数据皆可见，中间层数据不可见，因此也叫隐藏层。



### 1. 输入层

以上图二层神经网络为例，x1,x2,x3即为输入层，也是元数据，w1,w2,w3为参数，b为偏移量。输入层元数据x矩阵与w参数矩阵的积加上偏移量b，得到第一层的输出，此输出作为第二层即隐藏层的输入。即：


```
                                     z = w1*x1+w2*x2+w3*x3+b
```

### 2. 隐藏层
##### 2.1 激活函数
我们在进行神经网络计算时，前一层的输出往往会很大，这时我们可以通过一个激活函数将前层输出映射到一个较小的范围。使用一个神经网络时，我们需要决定使用哪种激活函数用在隐藏层，哪种激活函数用在输出层。Tensorflow中提供的常用激活函数有sigmoid,Relu,tanh等等。

![](/assets/TIM截图20180501001817.png)

sigmoid函数包含指数运算，计算量大，且当输出值很大时激活函数值接近饱和，学习速度慢，因此很多情况下我们都放弃选择sigmoid激活函数，而选择Relu,Relu梯度下降快，训练的学习速度更快。但当我们需要解决一个二分类问题时，选择sigmoid作为激活函数往往有更好的效果。

### 3.输出层
在输出层，我们定义一个loss损失函数，这个损失函数可以是预测值与真实值差的平方求均值，也可以是交叉熵。然后我们通过梯度下降的方式反复迭代，求得使损失函数loss最小时的参数w和b。神经网络的结构及运行我们大致了解这么多，下面我们通过Tensorflow来构造一个神经网络。

